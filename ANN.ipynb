{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16129, 127) (3871, 127)\n"
     ]
    }
   ],
   "source": [
    "roo = './roo1.csv'\n",
    "df  = pd.read_csv(roo)\n",
    "\n",
    "data      = df.copy()\n",
    "train_set = data.sample(frac=0.80645)\n",
    "test_set  = data.drop(train_set.index)\n",
    "\n",
    "# print ('Training set')\n",
    "# print (train_set.head())\n",
    "# print ('\\nTest set')\n",
    "# print (test_set.head())\n",
    "# print ('\\nOriginal DataFrame')\n",
    "# print (data.head())\n",
    "\n",
    "print(train_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:93]\n",
    "Y_train = train_set.iloc[:,93:]\n",
    "\n",
    "X_test  = test_set.iloc[:,:93]\n",
    "Y_test  = test_set.iloc[:,93:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape            : (16129, 127)\n",
      "test_set shape             : (3871, 127)\n",
      "Number of training examples: 16129\n",
      "Number of testing examples : 16129\n",
      "\n",
      "********************************************\n",
      "\n",
      "X_train shape: (16129, 93)\n",
      "Y_train shape: (16129, 34)\n",
      "X_test shape: (3871, 93)\n",
      "Y_test shape: (3871, 34)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "m_train = X_train.shape[0] #no of train samples\n",
    "n       = X_train.shape[1] #no of train features\n",
    "m_test  = Y_train.shape[0] #no of test samples\n",
    "\n",
    "print (\"train_set shape            : \" + str(train_set.shape))\n",
    "print (\"test_set shape             : \" + str(test_set.shape))\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples : \" + str(m_test))\n",
    "print (\"\\n********************************************\\n\")\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "#print(X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayali/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Acedamic percentage in Operating Systems  percentage in Algorithms  \\\n",
      "11456                                  0.038441                  0.206265   \n",
      "16528                                  0.051316                  0.038834   \n",
      "3253                                   0.192939                  0.180506   \n",
      "18614                                  0.102815                 -0.012683   \n",
      "1544                                  -0.219056                 -0.115717   \n",
      "\n",
      "       Percentage in Programming Concepts  Percentage in Software Engineering  \\\n",
      "11456                            0.089097                            0.062728   \n",
      "16528                           -0.103860                            0.152728   \n",
      "3253                            -0.090996                            0.075585   \n",
      "18614                            0.192007                           -0.117273   \n",
      "1544                            -0.219634                            0.127014   \n",
      "\n",
      "       Percentage in Computer Networks  Percentage in Electronics Subjects  \\\n",
      "11456                        -0.076770                           -0.077440   \n",
      "16528                         0.090740                           -0.167545   \n",
      "3253                         -0.141196                            0.089898   \n",
      "18614                         0.000542                            0.077026   \n",
      "1544                         -0.205623                           -0.077440   \n",
      "\n",
      "       Percentage in Computer Architecture  Percentage in Mathematics  \\\n",
      "11456                             0.050743                  -0.101955   \n",
      "16528                             0.063610                   0.001168   \n",
      "3253                             -0.168006                  -0.024613   \n",
      "18614                            -0.142271                   0.078511   \n",
      "1544                              0.166551                   0.168745   \n",
      "\n",
      "       Percentage in Communication skills  Hours working per day  \\\n",
      "11456                            0.116848                     12   \n",
      "16528                           -0.128016                      9   \n",
      "3253                            -0.153791                      4   \n",
      "18614                            0.142623                      6   \n",
      "1544                            -0.102241                      9   \n",
      "\n",
      "           ...        Management or Technical_Management  \\\n",
      "11456      ...                                         0   \n",
      "16528      ...                                         0   \n",
      "3253       ...                                         0   \n",
      "18614      ...                                         1   \n",
      "1544       ...                                         1   \n",
      "\n",
      "       Management or Technical_Technical  Salary/work_salary  \\\n",
      "11456                                  1                   0   \n",
      "16528                                  1                   0   \n",
      "3253                                   1                   0   \n",
      "18614                                  0                   1   \n",
      "1544                                   0                   0   \n",
      "\n",
      "       Salary/work_work  hard/smart worker_hard worker  \\\n",
      "11456                 1                              1   \n",
      "16528                 1                              0   \n",
      "3253                  1                              1   \n",
      "18614                 0                              1   \n",
      "1544                  1                              1   \n",
      "\n",
      "       hard/smart worker_smart worker  worked in teams ever?_no  \\\n",
      "11456                               0                         0   \n",
      "16528                               1                         0   \n",
      "3253                                0                         0   \n",
      "18614                               0                         1   \n",
      "1544                                0                         1   \n",
      "\n",
      "       worked in teams ever?_yes  Introvert_no  Introvert_yes  \n",
      "11456                          1             0              1  \n",
      "16528                          1             1              0  \n",
      "3253                           1             1              0  \n",
      "18614                          0             1              0  \n",
      "1544                           0             1              0  \n",
      "\n",
      "[5 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalising the marks columns (1-9)\n",
    "myu = [77.01426002852006, 76.98474796949594, 77.07384214768429, 77.12121024242049, 76.95790191580383, 77.01605803211606, 77.05654411308822, 76.90935581871163, 76.93328786657574]\n",
    "sig = [77.67089701771499, 77.64407546751336, 77.73767831813130, 77.77726209249717, 77.60748318199020, 77.68706969992881, 77.71482937759954, 77.57664974896230, 77.59417367116924]\n",
    " #array contains variance of all train columns\n",
    "\n",
    "for i in range(9):\n",
    "    X_train.iloc[:,i] = (X_train.iloc[:,i] - myu[i])/sig[i]\n",
    "    X_test.iloc[:,i] = (X_test.iloc[:,i] - myu[i])/sig[i]\n",
    "    \n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "#print(X_train.head())\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, no of features (93)\n",
    "    n_y -- scalar, number of classes (34)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(dtype = \"float32\" , shape = (n_x,None) , name=\"X\")\n",
    "    Y = tf.placeholder(dtype = \"float32\" , shape = (n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Tesing\n",
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [50, 93]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [45, 50]\n",
    "                        b2 : [45, 1]\n",
    "                        W3 : [40, 45]\n",
    "                        b3 : [40, 1]\n",
    "                        W4 : [38, 40]\n",
    "                        b4 : [38, 1]\n",
    "                        W5 : [36, 38]\n",
    "                        b5 : [36, 1]\n",
    "                        W6 : [34, 36]\n",
    "                        b6 : [34, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [50, 93], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [50, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [45, 50], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [45, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [40, 45], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b5 = tf.get_variable(\"b5\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W6 = tf.get_variable(\"W6\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b6 = tf.get_variable(\"b6\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W7 = tf.get_variable(\"W7\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b7 = tf.get_variable(\"b7\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W8 = tf.get_variable(\"W8\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b8 = tf.get_variable(\"b8\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W9 = tf.get_variable(\"W9\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b9 = tf.get_variable(\"b9\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W10 = tf.get_variable(\"W10\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b10 = tf.get_variable(\"b10\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W11 = tf.get_variable(\"W11\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b11 = tf.get_variable(\"b11\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W12 = tf.get_variable(\"W12\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b12 = tf.get_variable(\"b12\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W13 = tf.get_variable(\"W13\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b13 = tf.get_variable(\"b13\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W14 = tf.get_variable(\"W14\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b14 = tf.get_variable(\"b14\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W15 = tf.get_variable(\"W15\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b15 = tf.get_variable(\"b15\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W16 = tf.get_variable(\"W16\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b16 = tf.get_variable(\"b16\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W17 = tf.get_variable(\"W17\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b17 = tf.get_variable(\"b17\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W18 = tf.get_variable(\"W18\", [38, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b18 = tf.get_variable(\"b18\", [38, 1], initializer = tf.zeros_initializer())\n",
    "    W19 = tf.get_variable(\"W19\", [36, 38], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b19 = tf.get_variable(\"b19\", [36, 1], initializer = tf.zeros_initializer())\n",
    "    W20 = tf.get_variable(\"W20\", [34, 36], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b20 = tf.get_variable(\"b20\", [34, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2,\"W3\": W3,\"b3\": b3,\"W4\": W4,\"b4\": b4,\n",
    "                  \"W5\": W5,\"b5\": b5,\"W6\": W6,\"b6\": b6,\"W7\": W7,\"b7\": b7,\"W8\": W8,\"b8\": b8,\n",
    "                  \"W9\": W9,\"b9\": b9,\"W10\": W10,\"b10\": b10,\"W11\": W11,\"b11\": b11,\"W12\": W12,\"b12\": b12,\n",
    "                  \"W13\": W13,\"b13\": b13,\"W14\": W14,\"b14\": b14,\"W15\": W15,\"b15\": b15,\"W16\": W16,\"b16\": b16,\n",
    "                  \"W17\": W17,\"b17\": b17,\"W18\": W18,\"b18\": b18,\"W19\": W19,\"b19\": b19,\"W20\": W20,\"b20\": b20,\n",
    "                  }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W1 = <tf.Variable 'W1:0' shape=(50, 93) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(50, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(45, 50) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(45, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "#     print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "#     print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "#     print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "#     print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "    W7 = parameters['W7']\n",
    "    b7 = parameters['b7']\n",
    "    W8 = parameters['W8']\n",
    "    b8 = parameters['b8']\n",
    "    W9 = parameters['W9']\n",
    "    b9 = parameters['b9']\n",
    "    W10 = parameters['W10']\n",
    "    b10 = parameters['b10']\n",
    "    W11 = parameters['W11']\n",
    "    b11 = parameters['b11']\n",
    "    W12 = parameters['W12']\n",
    "    b12 = parameters['b12']\n",
    "    W13 = parameters['W13']\n",
    "    b13 = parameters['b13']\n",
    "    W14 = parameters['W14']\n",
    "    b14 = parameters['b14']\n",
    "    W15 = parameters['W15']\n",
    "    b15 = parameters['b15']\n",
    "    W16 = parameters['W16']\n",
    "    b16 = parameters['b16']\n",
    "    W17 = parameters['W17']\n",
    "    b17 = parameters['b17']\n",
    "    W18 = parameters['W18']\n",
    "    b18 = parameters['b18']\n",
    "    W19 = parameters['W19']\n",
    "    b19 = parameters['b19']\n",
    "    W20 = parameters['W20']\n",
    "    b20 = parameters['b20']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       # Z3 = np.dot(W3,a2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                    # A3 = relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)                       # Z4 = np.dot(W4,a3) + b4\n",
    "    A4 = tf.nn.relu(Z4)                                    # A4 = relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4),b5)                       # Z5 = np.dot(W5,a4) + b5\n",
    "    A5 = tf.nn.relu(Z5)                                    # A5 = relu(Z5)\n",
    "    Z6 = tf.add(tf.matmul(W6,A5),b6)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A6 = tf.nn.relu(Z6)                                    # A5 = relu(Z5)\n",
    "    Z7 = tf.add(tf.matmul(W7,A6),b7)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A7 = tf.nn.relu(Z7)                                    # A5 = relu(Z5)\n",
    "    Z8 = tf.add(tf.matmul(W8,A7),b8)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A8 = tf.nn.relu(Z8)                                    # A5 = relu(Z5)\n",
    "    Z9 = tf.add(tf.matmul(W9,A8),b9)\n",
    "    A9 = tf.nn.relu(Z9)                                    # A5 = relu(Z5)\n",
    "    Z10 = tf.add(tf.matmul(W10,A9),b10)\n",
    "    A10 = tf.nn.relu(Z10)                                    # A5 = relu(Z5)\n",
    "    Z11 = tf.add(tf.matmul(W11,A10),b11)\n",
    "    A11 = tf.nn.relu(Z11)                                    # A5 = relu(Z5)\n",
    "    Z12 = tf.add(tf.matmul(W12,A11),b12)\n",
    "    A12 = tf.nn.relu(Z12)                                    # A5 = relu(Z5)\n",
    "    Z13 = tf.add(tf.matmul(W13,A12),b13)\n",
    "    A13 = tf.nn.relu(Z13)                                    # A5 = relu(Z5)\n",
    "    Z14 = tf.add(tf.matmul(W14,A13),b14)\n",
    "    A14 = tf.nn.relu(Z14)                                    # A5 = relu(Z5)\n",
    "    Z15 = tf.add(tf.matmul(W15,A14),b15)\n",
    "    A15 = tf.nn.relu(Z15)                                    # A5 = relu(Z5)\n",
    "    Z16 = tf.add(tf.matmul(W16,A15),b16)\n",
    "    A16 = tf.nn.relu(Z16)                                    # A5 = relu(Z5)\n",
    "    Z17 = tf.add(tf.matmul(W17,A16),b17)\n",
    "    A17 = tf.nn.relu(Z17)                                    # A5 = relu(Z5)\n",
    "    Z18 = tf.add(tf.matmul(W18,A17),b18)\n",
    "    A18 = tf.nn.relu(Z18)                                    # A5 = relu(Z5)\n",
    "    Z19 = tf.add(tf.matmul(W19,A18),b19)\n",
    "    A19 = tf.nn.relu(Z19)                                    # A5 = relu(Z5)\n",
    "    Z20 = tf.add(tf.matmul(W20,A19),b20)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z8 = Tensor(\"Add_7:0\", shape=(34, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z12 = forward_propagation(X, parameters)\n",
    "    print(\"Z12 = \" + str(Z12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z20, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (34, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z20)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)...\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z12 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z12, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 512, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    k = 0\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X.iloc[:, permutation]\n",
    "    shuffled_Y = Y.iloc[:, permutation]\n",
    "#.reshape((1,m))\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 16129)\n",
      "(34, 16129)\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.001,\n",
    "          num_epochs = 2000, minibatch_size = 102, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a four-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 93, number of training examples = 16129)\n",
    "    Y_train -- test set, of shape (output size = 34, number of training examples = 16129)\n",
    "    X_test -- training set, of shape (input size = 93, number of training examples = 3871)\n",
    "    Y_test -- test set, of shape (output size = 34, number of test examples = 3871)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #print(\"here \",X.shape)\n",
    "    Z20 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z20, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z20), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "        print (\"Train Accuracy : \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy  : \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print (\"Learning_rate  : \",learning_rate)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 16129)\n",
      "Cost after epoch 0: 3.637517\n",
      "Cost after epoch 100: 3.093879\n",
      "Cost after epoch 200: 2.804501\n",
      "Cost after epoch 300: 2.590879\n",
      "Cost after epoch 400: 2.524533\n",
      "Cost after epoch 500: 2.366439\n",
      "Cost after epoch 600: 2.345501\n",
      "Cost after epoch 700: 2.318513\n",
      "Cost after epoch 800: 2.256652\n",
      "Cost after epoch 900: 2.257266\n",
      "Cost after epoch 1000: 2.236304\n",
      "Cost after epoch 1100: 2.160256\n",
      "Cost after epoch 1200: 2.132820\n",
      "Cost after epoch 1300: 2.190674\n",
      "Cost after epoch 1400: 2.100132\n",
      "Cost after epoch 1500: 2.122005\n",
      "Cost after epoch 1600: 2.198519\n",
      "Cost after epoch 1700: 2.285104\n",
      "Cost after epoch 1800: 2.088538\n",
      "Cost after epoch 1900: 2.065430\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy :  0.37324074\n",
      "Test Accuracy  :  0.028933093\n",
      "Learning_rate  :  0.001\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
