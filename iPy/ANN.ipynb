{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14992, 66) (5008, 66)\n"
     ]
    }
   ],
   "source": [
    "tr = '../Data/train.csv'\n",
    "ts = '../Data/test.csv'\n",
    "train_set = pd.read_csv(tr)\n",
    "test_set  = pd.read_csv(ts)\n",
    "\n",
    "# print ('Training set')\n",
    "# print (train_set.head())\n",
    "# print ('\\nTest set')\n",
    "# print (test_set.head())\n",
    "# print ('\\nOriginal DataFrame')\n",
    "# print (data.head())\n",
    "\n",
    "print(train_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:58]\n",
    "Y_train = train_set.iloc[:,58:]\n",
    "\n",
    "X_test  = test_set.iloc[:,:58]\n",
    "Y_test  = test_set.iloc[:,58:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (58, 14992)\n",
      "Y_train shape: (8, 14992)\n",
      "X_test shape: (58, 5008)\n",
      "Y_test shape: (8, 5008)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "\n",
    "m_train = X_train.shape[1] #no of train samples\n",
    "n       = X_train.shape[0] #no of train features\n",
    "m_test  = Y_test.shape[1] #no of test samples\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "# print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the marks columns (1-9)\n",
    "# myu = [77.02508004268944,  76.95090715048026,  77.03868729989328,  77.13046958377801, 76.94223585912486,  77.0510272145144,   76.92062433297758,  76.91355389541089, 7.981456776947706,  5.005803094983992,  2.974919957310566,  5.009271611526147, 5.001867662753469]\n",
    "# sig = [10.069482344113009, 10.100838612474481, 10.155240754077084, 10.10313965184933, 10.008561395008378, 10.105803974768442, 10.159253374201388, 10.09967655273072, 2.5876773324068223, 2.5826669245403986, 2.0067022963210617, 2.576243318124351, 2.577799489969915]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "#print(X_train.head())\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, no of features (93)\n",
    "    n_y -- scalar, number of classes (34)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(dtype = \"float32\" , shape = (n_x,None) , name=\"X\")\n",
    "    Y = tf.placeholder(dtype = \"float32\" , shape = (n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Tesing\n",
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [50, 93]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [45, 50]\n",
    "                        b2 : [45, 1]\n",
    "                        W3 : [40, 45]\n",
    "                        b3 : [40, 1]\n",
    "                        W4 : [38, 40]\n",
    "                        b4 : [38, 1]\n",
    "                        W5 : [36, 38]\n",
    "                        b5 : [36, 1]\n",
    "                        W6 : [34, 36]\n",
    "                        b6 : [34, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [100, 58], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [80, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [80, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [70, 80], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [70, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [60, 70], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [60, 1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [50, 60], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b5 = tf.get_variable(\"b5\", [50, 1], initializer = tf.zeros_initializer())\n",
    "    W6 = tf.get_variable(\"W6\", [40, 50], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b6 = tf.get_variable(\"b6\", [40, 1], initializer = tf.zeros_initializer())\n",
    "    W7 = tf.get_variable(\"W7\", [30, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b7 = tf.get_variable(\"b7\", [30, 1], initializer = tf.zeros_initializer())\n",
    "    W8 = tf.get_variable(\"W8\", [20, 30], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b8 = tf.get_variable(\"b8\", [20, 1], initializer = tf.zeros_initializer())\n",
    "    W9 = tf.get_variable(\"W9\", [10, 20], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b9 = tf.get_variable(\"b9\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    W10 = tf.get_variable(\"W10\", [8, 10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b10 = tf.get_variable(\"b10\", [8, 1], initializer = tf.zeros_initializer())\n",
    "#     W11 = tf.get_variable(\"W11\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b11 = tf.get_variable(\"b11\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W12 = tf.get_variable(\"W12\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b12 = tf.get_variable(\"b12\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W13 = tf.get_variable(\"W13\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b13 = tf.get_variable(\"b13\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W14 = tf.get_variable(\"W14\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b14 = tf.get_variable(\"b14\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W15 = tf.get_variable(\"W15\", [8, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b15 = tf.get_variable(\"b15\", [8, 1], initializer = tf.zeros_initializer())\n",
    "#     W16 = tf.get_variable(\"W16\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b16 = tf.get_variable(\"b16\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W17 = tf.get_variable(\"W17\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b17 = tf.get_variable(\"b17\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W18 = tf.get_variable(\"W18\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b18 = tf.get_variable(\"b18\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W19 = tf.get_variable(\"W19\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b19 = tf.get_variable(\"b19\", [100, 1], initializer = tf.zeros_initializer())\n",
    "#     W20 = tf.get_variable(\"W20\", [34, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b20 = tf.get_variable(\"b20\", [34, 1], initializer = tf.zeros_initializer())\n",
    "#     W21 = tf.get_variable(\"W21\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b21 = tf.get_variable(\"b21\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W22 = tf.get_variable(\"W22\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b22 = tf.get_variable(\"b22\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W23 = tf.get_variable(\"W23\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b23 = tf.get_variable(\"b23\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W24 = tf.get_variable(\"W24\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b24 = tf.get_variable(\"b24\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W25 = tf.get_variable(\"W25\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b25 = tf.get_variable(\"b25\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W26 = tf.get_variable(\"W26\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b26 = tf.get_variable(\"b26\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W27 = tf.get_variable(\"W27\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b27 = tf.get_variable(\"b27\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W28 = tf.get_variable(\"W28\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b28 = tf.get_variable(\"b28\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W29 = tf.get_variable(\"W29\", [38, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b29 = tf.get_variable(\"b29\", [38, 1], initializer = tf.zeros_initializer())\n",
    "#     W30 = tf.get_variable(\"W30\", [36, 38], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b30 = tf.get_variable(\"b30\", [36, 1], initializer = tf.zeros_initializer())\n",
    "#     W31 = tf.get_variable(\"W31\", [34, 36], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b31 = tf.get_variable(\"b31\", [34, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2,\"W3\": W3,\"b3\": b3,\"W4\": W4,\"b4\": b4,\n",
    "                  \"W5\": W5,\"b5\": b5,\"W6\": W6,\"b6\": b6,\"W7\": W7,\"b7\": b7,\"W8\": W8,\"b8\": b8,\n",
    "                  \"W9\": W9,\"b9\": b9,\"W10\": W10,\"b10\": b10,\n",
    "#                   \"W11\": W11,\"b11\": b11,\"W12\": W12,\"b12\": b12,\n",
    "#                   \"W13\":W13,\"b13\":b13,\"W14\": W14,\"b14\": b14,\"W15\": W15,\"b15\": b15,\n",
    "#                   \"W16\": W16,\"b16\": b16,\n",
    "#                   \"W17\":W17,\"b17\":b17,\"W18\": W18,\"b18\": b18,\"W19\": W19,\"b19\": b19,\"W20\": W20,\"b20\": b20,\n",
    "#                   \"W21\":W21,\"b21\":b21,\"W22\":W22,\"b22\":b22,\"W23\":W23,\"b23\":b23,\"W24\":W24,\"b24\":b24,\n",
    "#                   \"W25\":W25,\"b25\":b25,\"W26\":W26,\"b26\":b26,\"W27\":W27,\"b27\":b27,\"W28\":W28,\"b28\":b28,\n",
    "#                   \"W29\":W29,\"b29\":b29,\"W30\":W30,\"b30\":b30,\"W31\":W31,\"b31\":b31\n",
    "#                  \n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W19'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b986eedb1a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W19 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W19\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b19 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b19\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W20 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W20\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'W19'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W19 = \" + str(parameters[\"W19\"]))\n",
    "    print(\"b19 = \" + str(parameters[\"b19\"]))\n",
    "    print(\"W20 = \" + str(parameters[\"W20\"]))\n",
    "    print(\"b20 = \" + str(parameters[\"b20\"]))\n",
    "#     print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "#     print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "#     print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "#     print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "    W7 = parameters['W7']\n",
    "    b7 = parameters['b7']\n",
    "    W8 = parameters['W8']\n",
    "    b8 = parameters['b8']\n",
    "    W9 = parameters['W9']\n",
    "    b9 = parameters['b9']\n",
    "    W10 = parameters['W10']\n",
    "    b10 = parameters['b10']\n",
    "#     W11 = parameters['W11']\n",
    "#     b11 = parameters['b11']\n",
    "#     W12 = parameters['W12']\n",
    "#     b12 = parameters['b12']\n",
    "#     W13 = parameters['W13']\n",
    "#     b13 = parameters['b13']\n",
    "#     W14 = parameters['W14']\n",
    "#     b14 = parameters['b14']\n",
    "#     W15 = parameters['W15']\n",
    "#     b15 = parameters['b15']\n",
    "#     W16 = parameters['W16']\n",
    "#     b16 = parameters['b16']\n",
    "#     W17 = parameters['W17']\n",
    "#     b17 = parameters['b17']\n",
    "#     W18 = parameters['W18']\n",
    "#     b18 = parameters['b18']\n",
    "#     W19 = parameters['W19']\n",
    "#     b19 = parameters['b19']\n",
    "#     W20 = parameters['W20']\n",
    "#     b20 = parameters['b20']\n",
    "#     W21 = parameters['W21']\n",
    "#     b21 = parameters['b21']\n",
    "#     W22 = parameters['W22']\n",
    "#     b22 = parameters['b22']\n",
    "#     W23 = parameters['W23']\n",
    "#     b23 = parameters['b23']\n",
    "#     W24 = parameters['W24']\n",
    "#     b24 = parameters['b24']\n",
    "#     W25 = parameters['W25']\n",
    "#     b25 = parameters['b25']\n",
    "#     W26 = parameters['W26']\n",
    "#     b26 = parameters['b26']\n",
    "#     W27 = parameters['W27']\n",
    "#     b27 = parameters['b27']\n",
    "#     W28 = parameters['W28']\n",
    "#     b28 = parameters['b28']\n",
    "#     W29 = parameters['W29']\n",
    "#     b29 = parameters['b29']\n",
    "#     W30 = parameters['W30']\n",
    "#     b30 = parameters['b30']\n",
    "#     W31 = parameters['W31']\n",
    "#     b31 = parameters['b31']\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       # Z3 = np.dot(W3,a2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                    # A3 = relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)                       # Z4 = np.dot(W4,a3) + b4\n",
    "    A4 = tf.nn.relu(Z4)                                    # A4 = relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4),b5)                       # Z5 = np.dot(W5,a4) + b5\n",
    "    A5 = tf.nn.relu(Z5)                                    # A5 = relu(Z5)\n",
    "    Z6 = tf.add(tf.matmul(W6,A5),b6)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A6 = tf.nn.relu(Z6)                                    # A5 = relu(Z5)\n",
    "    Z7 = tf.add(tf.matmul(W7,A6),b7)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A7 = tf.nn.relu(Z7)                                    # A5 = relu(Z5)\n",
    "    Z8 = tf.add(tf.matmul(W8,A7),b8)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A8 = tf.nn.relu(Z8)                                    # A5 = relu(Z5)\n",
    "    Z9 = tf.add(tf.matmul(W9,A8),b9)\n",
    "    A9 = tf.nn.relu(Z9)                                    # A5 = relu(Z5)\n",
    "    Z10 = tf.add(tf.matmul(W10,A9),b10)\n",
    "#     A10 = tf.nn.relu(Z10)                                    # A5 = relu(Z5)\n",
    "#     Z11 = tf.add(tf.matmul(W11,A10),b11)\n",
    "#     A11 = tf.nn.relu(Z11)                                    # A5 = relu(Z5)\n",
    "#     Z12 = tf.add(tf.matmul(W12,A11),b12)\n",
    "#     A12 = tf.nn.relu(Z12)                                    # A5 = relu(Z5)\n",
    "#     Z13 = tf.add(tf.matmul(W13,A12),b13)\n",
    "#     A13 = tf.nn.relu(Z13)                                    # A5 = relu(Z5)\n",
    "#     Z14 = tf.add(tf.matmul(W14,A13),b14)\n",
    "#     A14 = tf.nn.relu(Z14)                                    # A5 = relu(Z5)\n",
    "#     Z15 = tf.add(tf.matmul(W15,A14),b15)\n",
    "#     A15 = tf.nn.relu(Z15)                                    # A5 = relu(Z5)\n",
    "#     Z16 = tf.add(tf.matmul(W16,A15),b16)\n",
    "#     A16 = tf.nn.relu(Z16)                                    # A5 = relu(Z5)\n",
    "#     Z17 = tf.add(tf.matmul(W17,A16),b17)\n",
    "#     A17 = tf.nn.relu(Z17)                                    # A5 = relu(Z5)\n",
    "#     Z18 = tf.add(tf.matmul(W18,A17),b18)\n",
    "#     A18 = tf.nn.relu(Z18)                                    # A5 = relu(Z5)\n",
    "#     Z19 = tf.add(tf.matmul(W19,A18),b19)\n",
    "#     A19 = tf.nn.relu(Z19)\n",
    "#     Z20 = tf.add(tf.matmul(W20,A19),b20)\n",
    "#     A20 = tf.nn.relu(Z20)                                    # A5 = relu(Z5)\n",
    "#     Z21 = tf.add(tf.matmul(W21,A20),b21)\n",
    "#     A21 = tf.nn.relu(Z21)                                    # A5 = relu(Z5)\n",
    "#     Z22 = tf.add(tf.matmul(W22,A21),b22)\n",
    "#     A22 = tf.nn.relu(Z22)\n",
    "#     Z23 = tf.add(tf.matmul(W23,A22),b23)\n",
    "#     A23 = tf.nn.relu(Z23)                                    # A5 = relu(Z5)\n",
    "#     Z24 = tf.add(tf.matmul(W24,A23),b24)\n",
    "#     A24 = tf.nn.relu(Z24)                                    # A5 = relu(Z5)\n",
    "#     Z25 = tf.add(tf.matmul(W25,A24),b25)\n",
    "#     A25 = tf.nn.relu(Z25)                                    # A5 = relu(Z5)\n",
    "#     Z26 = tf.add(tf.matmul(W26,A25),b26)\n",
    "#     A26 = tf.nn.relu(Z26)                                    # A5 = relu(Z5)\n",
    "#     Z27 = tf.add(tf.matmul(W27,A26),b27)\n",
    "#     A27 = tf.nn.relu(Z27)                                    # A5 = relu(Z5)\n",
    "#     Z28 = tf.add(tf.matmul(W28,A27),b28)\n",
    "#     A28 = tf.nn.relu(Z28)                                    # A5 = relu(Z5)\n",
    "#     Z29 = tf.add(tf.matmul(W29,A28),b29)\n",
    "#     A29 = tf.nn.relu(Z29)                                    # A5 = relu(Z5)\n",
    "#     Z30 = tf.add(tf.matmul(W30,A29),b30)\n",
    "#     A30 = tf.nn.relu(Z30)                                    # A5 = relu(Z5)\n",
    "#     Z31 = tf.add(tf.matmul(W31,A30),b31)\n",
    "#     ### END CODE HERE ###\n",
    "    \n",
    "    return Z10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z12 = Tensor(\"Add_19:0\", shape=(34, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z12 = forward_propagation(X, parameters)\n",
    "    print(\"Z12 = \" + str(Z12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z31, Y, params):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (34, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z31)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)...\n",
    "    n = len(params)//2\n",
    "    regularizer = 0\n",
    "    for x in range(n):\n",
    "        regularizer = regularizer + tf.nn.l2_loss(params['W'+str(x+1)])\n",
    "    regularizer = tf.nn.l2_loss(params['W'+str(n)])\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels) + 0.01*regularizer)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-ff98a105d657>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z31 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z31, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 512, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    k = 0\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X.iloc[:, permutation]\n",
    "    shuffled_Y = Y.iloc[:, permutation]\n",
    "#.reshape((1,m))\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 14992)\n",
      "(8, 14992)\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 500, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a four-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 93, number of training examples = 16129)\n",
    "    Y_train -- test set, of shape (output size = 34, number of training examples = 16129)\n",
    "    X_test -- training set, of shape (input size = 93, number of training examples = 3871)\n",
    "    Y_test -- test set, of shape (output size = 34, number of test examples = 3871)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(0)                             # to keep consistent results\n",
    "    seed = 2                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #print(\"here \",X.shape)\n",
    "    Z10 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z10, Y, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z10), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "        print (\"Train Accuracy : \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy  : \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print (\"Learning_rate  : \",learning_rate)\n",
    "        print (\"Batch Size     : \",minibatch_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 14992)\n",
      "Cost after epoch 0: 2.189286\n",
      "Cost after epoch 100: 1.865582\n",
      "Cost after epoch 200: 1.632732\n",
      "Cost after epoch 300: 1.442156\n",
      "Cost after epoch 400: 1.268755\n",
      "Cost after epoch 500: 1.125981\n",
      "Cost after epoch 600: 1.005250\n",
      "Cost after epoch 700: 0.900096\n",
      "Cost after epoch 800: 0.806476\n",
      "Cost after epoch 900: 0.724559\n",
      "Cost after epoch 1000: 0.643406\n",
      "Cost after epoch 1100: 0.584753\n",
      "Cost after epoch 1200: 0.521504\n",
      "Cost after epoch 1300: 0.485584\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) \n",
    "parameters= model(X_train, Y_train, X_test, Y_test,num_epochs = 1500)\n",
    "#24,20,2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns\n",
    "\n",
    "# y_Actual = \n",
    "# df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "# confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "# sn.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Y' with dtype float and shape [34,?]\n\t [[node Y (defined at <ipython-input-31-58a4882e9e88>:29) ]]\n\nCaused by op 'Y', defined at:\n  File \"/home/sayali/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sayali/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-09dcd1bee0ed>\", line 2, in <module>\n    parameters,conf = model(X_train, Y_train, X_test, Y_test,num_epochs = 1001)\n  File \"<ipython-input-31-58a4882e9e88>\", line 29, in model\n    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Y' with dtype float and shape [34,?]\n\t [[node Y (defined at <ipython-input-31-58a4882e9e88>:29) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Y' with dtype float and shape [34,?]\n\t [[{{node Y}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-49636eb7a770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Y' with dtype float and shape [34,?]\n\t [[node Y (defined at <ipython-input-31-58a4882e9e88>:29) ]]\n\nCaused by op 'Y', defined at:\n  File \"/home/sayali/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sayali/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/sayali/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-09dcd1bee0ed>\", line 2, in <module>\n    parameters,conf = model(X_train, Y_train, X_test, Y_test,num_epochs = 1001)\n  File \"<ipython-input-31-58a4882e9e88>\", line 29, in model\n    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Y' with dtype float and shape [34,?]\n\t [[node Y (defined at <ipython-input-31-58a4882e9e88>:29) ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "        print(sess.run(conf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
