{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14960, 127) (5040, 127)\n"
     ]
    }
   ],
   "source": [
    "tr = '../Data/train.csv'\n",
    "ts = '../Data/test.csv'\n",
    "train_set = pd.read_csv(tr)\n",
    "test_set  = pd.read_csv(ts)\n",
    "\n",
    "# print ('Training set')\n",
    "# print (train_set.head())\n",
    "# print ('\\nTest set')\n",
    "# print (test_set.head())\n",
    "# print ('\\nOriginal DataFrame')\n",
    "# print (data.head())\n",
    "\n",
    "print(train_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:93]\n",
    "Y_train = train_set.iloc[:,93:]\n",
    "\n",
    "X_test  = test_set.iloc[:,:93]\n",
    "Y_test  = test_set.iloc[:,93:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape            : (14960, 127)\n",
      "test_set shape             : (5040, 127)\n",
      "Number of training examples: 14960\n",
      "Number of testing examples : 5040\n",
      "\n",
      "********************************************\n",
      "\n",
      "X_train shape: (93, 14960)\n",
      "Y_train shape: (34, 14960)\n",
      "X_test shape: (93, 5040)\n",
      "Y_test shape: (34, 5040)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "\n",
    "m_train = X_train.shape[1] #no of train samples\n",
    "n       = X_train.shape[0] #no of train features\n",
    "m_test  = Y_test.shape[1] #no of test samples\n",
    "\n",
    "print (\"train_set shape            : \" + str(train_set.shape))\n",
    "print (\"test_set shape             : \" + str(test_set.shape))\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples : \" + str(m_test))\n",
    "print (\"\\n********************************************\\n\")\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "#print(Y_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the marks columns (1-9)\n",
    "myu = [77.01333333333334, 76.96693333333333, 77.03626666666666, 77.10393333333333, 76.9222,          77.0074,           77.04806666666667, 76.92826666666667, 76.9128]\n",
    "sig = [77.66900969284124, 77.62744188322410, 77.70232772146105, 77.76290075179381, 77.5714290186793, 77.67784282964266, 77.70757963888293, 77.59615883964017, 77.57365790008875]\n",
    "#array contains variance of all train columns\n",
    "\n",
    "# for i in range(9):\n",
    "#     X_train.iloc[:,i] = (X_train.iloc[:,i] - myu[i])/sig[i]\n",
    "#     X_test.iloc[:,i] = (X_test.iloc[:,i] - myu[i])/sig[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "#print(X_train.head())\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, no of features (93)\n",
    "    n_y -- scalar, number of classes (34)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(dtype = \"float32\" , shape = (n_x,None) , name=\"X\")\n",
    "    Y = tf.placeholder(dtype = \"float32\" , shape = (n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Tesing\n",
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [50, 93]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [45, 50]\n",
    "                        b2 : [45, 1]\n",
    "                        W3 : [40, 45]\n",
    "                        b3 : [40, 1]\n",
    "                        W4 : [38, 40]\n",
    "                        b4 : [38, 1]\n",
    "                        W5 : [36, 38]\n",
    "                        b5 : [36, 1]\n",
    "                        W6 : [34, 36]\n",
    "                        b6 : [34, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [100, 93], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b5 = tf.get_variable(\"b5\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W6 = tf.get_variable(\"W6\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b6 = tf.get_variable(\"b6\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W7 = tf.get_variable(\"W7\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b7 = tf.get_variable(\"b7\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W8 = tf.get_variable(\"W8\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b8 = tf.get_variable(\"b8\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W9 = tf.get_variable(\"W9\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b9 = tf.get_variable(\"b9\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W10 = tf.get_variable(\"W10\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b10 = tf.get_variable(\"b10\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W11 = tf.get_variable(\"W11\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b11 = tf.get_variable(\"b11\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W12 = tf.get_variable(\"W12\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b12 = tf.get_variable(\"b12\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W13 = tf.get_variable(\"W13\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b13 = tf.get_variable(\"b13\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W14 = tf.get_variable(\"W14\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b14 = tf.get_variable(\"b14\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W15 = tf.get_variable(\"W15\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b15 = tf.get_variable(\"b15\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W16 = tf.get_variable(\"W16\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b16 = tf.get_variable(\"b16\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W17 = tf.get_variable(\"W17\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b17 = tf.get_variable(\"b17\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W18 = tf.get_variable(\"W18\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b18 = tf.get_variable(\"b18\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W19 = tf.get_variable(\"W19\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b19 = tf.get_variable(\"b19\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W20 = tf.get_variable(\"W20\", [34, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b20 = tf.get_variable(\"b20\", [34, 1], initializer = tf.zeros_initializer())\n",
    "#     W21 = tf.get_variable(\"W21\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b21 = tf.get_variable(\"b21\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W22 = tf.get_variable(\"W22\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b22 = tf.get_variable(\"b22\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W23 = tf.get_variable(\"W23\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b23 = tf.get_variable(\"b23\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W24 = tf.get_variable(\"W24\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b24 = tf.get_variable(\"b24\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W25 = tf.get_variable(\"W25\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b25 = tf.get_variable(\"b25\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W26 = tf.get_variable(\"W26\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b26 = tf.get_variable(\"b26\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W27 = tf.get_variable(\"W27\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b27 = tf.get_variable(\"b27\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W28 = tf.get_variable(\"W28\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b28 = tf.get_variable(\"b28\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W29 = tf.get_variable(\"W29\", [38, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b29 = tf.get_variable(\"b29\", [38, 1], initializer = tf.zeros_initializer())\n",
    "#     W30 = tf.get_variable(\"W30\", [36, 38], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b30 = tf.get_variable(\"b30\", [36, 1], initializer = tf.zeros_initializer())\n",
    "#     W31 = tf.get_variable(\"W31\", [34, 36], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b31 = tf.get_variable(\"b31\", [34, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2,\"W3\": W3,\"b3\": b3,\"W4\": W4,\"b4\": b4,\n",
    "                  \"W5\": W5,\"b5\": b5,\"W6\": W6,\"b6\": b6,\"W7\": W7,\"b7\": b7,\"W8\": W8,\"b8\": b8,\n",
    "                  \"W9\": W9,\"b9\": b9,\"W10\": W10,\"b10\": b10,\"W11\": W11,\"b11\": b11,\"W12\": W12,\"b12\": b12,\n",
    "                  \"W13\":W13,\"b13\":b13,\"W14\": W14,\"b14\": b14,\"W15\": W15,\"b15\": b15,\"W16\": W16,\"b16\": b16,\n",
    "                  \"W17\":W17,\"b17\":b17,\"W18\": W18,\"b18\": b18,\"W19\": W19,\"b19\": b19,\"W20\": W20,\"b20\": b20,\n",
    "#                   \"W21\":W21,\"b21\":b21,\"W22\":W22,\"b22\":b22,\"W23\":W23,\"b23\":b23,\"W24\":W24,\"b24\":b24,\n",
    "#                   \"W25\":W25,\"b25\":b25,\"W26\":W26,\"b26\":b26,\"W27\":W27,\"b27\":b27,\"W28\":W28,\"b28\":b28,\n",
    "#                   \"W29\":W29,\"b29\":b29,\"W30\":W30,\"b30\":b30,\"W31\":W31,\"b31\":b31\n",
    "#                  \n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W19 = <tf.Variable 'W19:0' shape=(100, 100) dtype=float32_ref>\n",
      "b19 = <tf.Variable 'b19:0' shape=(100, 1) dtype=float32_ref>\n",
      "W20 = <tf.Variable 'W20:0' shape=(34, 100) dtype=float32_ref>\n",
      "b20 = <tf.Variable 'b20:0' shape=(34, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W19 = \" + str(parameters[\"W19\"]))\n",
    "    print(\"b19 = \" + str(parameters[\"b19\"]))\n",
    "    print(\"W20 = \" + str(parameters[\"W20\"]))\n",
    "    print(\"b20 = \" + str(parameters[\"b20\"]))\n",
    "#     print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "#     print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "#     print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "#     print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "    W7 = parameters['W7']\n",
    "    b7 = parameters['b7']\n",
    "    W8 = parameters['W8']\n",
    "    b8 = parameters['b8']\n",
    "    W9 = parameters['W9']\n",
    "    b9 = parameters['b9']\n",
    "    W10 = parameters['W10']\n",
    "    b10 = parameters['b10']\n",
    "    W11 = parameters['W11']\n",
    "    b11 = parameters['b11']\n",
    "    W12 = parameters['W12']\n",
    "    b12 = parameters['b12']\n",
    "    W13 = parameters['W13']\n",
    "    b13 = parameters['b13']\n",
    "    W14 = parameters['W14']\n",
    "    b14 = parameters['b14']\n",
    "    W15 = parameters['W15']\n",
    "    b15 = parameters['b15']\n",
    "    W16 = parameters['W16']\n",
    "    b16 = parameters['b16']\n",
    "    W17 = parameters['W17']\n",
    "    b17 = parameters['b17']\n",
    "    W18 = parameters['W18']\n",
    "    b18 = parameters['b18']\n",
    "    W19 = parameters['W19']\n",
    "    b19 = parameters['b19']\n",
    "    W20 = parameters['W20']\n",
    "    b20 = parameters['b20']\n",
    "#     W21 = parameters['W21']\n",
    "#     b21 = parameters['b21']\n",
    "#     W22 = parameters['W22']\n",
    "#     b22 = parameters['b22']\n",
    "#     W23 = parameters['W23']\n",
    "#     b23 = parameters['b23']\n",
    "#     W24 = parameters['W24']\n",
    "#     b24 = parameters['b24']\n",
    "#     W25 = parameters['W25']\n",
    "#     b25 = parameters['b25']\n",
    "#     W26 = parameters['W26']\n",
    "#     b26 = parameters['b26']\n",
    "#     W27 = parameters['W27']\n",
    "#     b27 = parameters['b27']\n",
    "#     W28 = parameters['W28']\n",
    "#     b28 = parameters['b28']\n",
    "#     W29 = parameters['W29']\n",
    "#     b29 = parameters['b29']\n",
    "#     W30 = parameters['W30']\n",
    "#     b30 = parameters['b30']\n",
    "#     W31 = parameters['W31']\n",
    "#     b31 = parameters['b31']\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       # Z3 = np.dot(W3,a2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                    # A3 = relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)                       # Z4 = np.dot(W4,a3) + b4\n",
    "    A4 = tf.nn.relu(Z4)                                    # A4 = relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4),b5)                       # Z5 = np.dot(W5,a4) + b5\n",
    "    A5 = tf.nn.relu(Z5)                                    # A5 = relu(Z5)\n",
    "    Z6 = tf.add(tf.matmul(W6,A5),b6)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A6 = tf.nn.relu(Z6)                                    # A5 = relu(Z5)\n",
    "    Z7 = tf.add(tf.matmul(W7,A6),b7)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A7 = tf.nn.relu(Z7)                                    # A5 = relu(Z5)\n",
    "    Z8 = tf.add(tf.matmul(W8,A7),b8)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A8 = tf.nn.relu(Z8)                                    # A5 = relu(Z5)\n",
    "    Z9 = tf.add(tf.matmul(W9,A8),b9)\n",
    "    A9 = tf.nn.relu(Z9)                                    # A5 = relu(Z5)\n",
    "    Z10 = tf.add(tf.matmul(W10,A9),b10)\n",
    "    A10 = tf.nn.relu(Z10)                                    # A5 = relu(Z5)\n",
    "    Z11 = tf.add(tf.matmul(W11,A10),b11)\n",
    "    A11 = tf.nn.relu(Z11)                                    # A5 = relu(Z5)\n",
    "    Z12 = tf.add(tf.matmul(W12,A11),b12)\n",
    "    A12 = tf.nn.relu(Z12)                                    # A5 = relu(Z5)\n",
    "    Z13 = tf.add(tf.matmul(W13,A12),b13)\n",
    "    A13 = tf.nn.relu(Z13)                                    # A5 = relu(Z5)\n",
    "    Z14 = tf.add(tf.matmul(W14,A13),b14)\n",
    "    A14 = tf.nn.relu(Z14)                                    # A5 = relu(Z5)\n",
    "    Z15 = tf.add(tf.matmul(W15,A14),b15)\n",
    "    A15 = tf.nn.relu(Z15)                                    # A5 = relu(Z5)\n",
    "    Z16 = tf.add(tf.matmul(W16,A15),b16)\n",
    "    A16 = tf.nn.relu(Z16)                                    # A5 = relu(Z5)\n",
    "    Z17 = tf.add(tf.matmul(W17,A16),b17)\n",
    "    A17 = tf.nn.relu(Z17)                                    # A5 = relu(Z5)\n",
    "    Z18 = tf.add(tf.matmul(W18,A17),b18)\n",
    "    A18 = tf.nn.relu(Z18)                                    # A5 = relu(Z5)\n",
    "    Z19 = tf.add(tf.matmul(W19,A18),b19)\n",
    "    A19 = tf.nn.relu(Z19)\n",
    "    Z20 = tf.add(tf.matmul(W20,A19),b20)\n",
    "#     A20 = tf.nn.relu(Z20)                                    # A5 = relu(Z5)\n",
    "#     Z21 = tf.add(tf.matmul(W21,A20),b21)\n",
    "#     A21 = tf.nn.relu(Z21)                                    # A5 = relu(Z5)\n",
    "#     Z22 = tf.add(tf.matmul(W22,A21),b22)\n",
    "#     A22 = tf.nn.relu(Z22)\n",
    "#     Z23 = tf.add(tf.matmul(W23,A22),b23)\n",
    "#     A23 = tf.nn.relu(Z23)                                    # A5 = relu(Z5)\n",
    "#     Z24 = tf.add(tf.matmul(W24,A23),b24)\n",
    "#     A24 = tf.nn.relu(Z24)                                    # A5 = relu(Z5)\n",
    "#     Z25 = tf.add(tf.matmul(W25,A24),b25)\n",
    "#     A25 = tf.nn.relu(Z25)                                    # A5 = relu(Z5)\n",
    "#     Z26 = tf.add(tf.matmul(W26,A25),b26)\n",
    "#     A26 = tf.nn.relu(Z26)                                    # A5 = relu(Z5)\n",
    "#     Z27 = tf.add(tf.matmul(W27,A26),b27)\n",
    "#     A27 = tf.nn.relu(Z27)                                    # A5 = relu(Z5)\n",
    "#     Z28 = tf.add(tf.matmul(W28,A27),b28)\n",
    "#     A28 = tf.nn.relu(Z28)                                    # A5 = relu(Z5)\n",
    "#     Z29 = tf.add(tf.matmul(W29,A28),b29)\n",
    "#     A29 = tf.nn.relu(Z29)                                    # A5 = relu(Z5)\n",
    "#     Z30 = tf.add(tf.matmul(W30,A29),b30)\n",
    "#     A30 = tf.nn.relu(Z30)                                    # A5 = relu(Z5)\n",
    "#     Z31 = tf.add(tf.matmul(W31,A30),b31)\n",
    "#     ### END CODE HERE ###\n",
    "    \n",
    "    return Z20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z12 = Tensor(\"Add_19:0\", shape=(34, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z12 = forward_propagation(X, parameters)\n",
    "    print(\"Z12 = \" + str(Z12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z31, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (34, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z31)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)...\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-ff98a105d657>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z31 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z31, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 512, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    k = 0\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X.iloc[:, permutation]\n",
    "    shuffled_Y = Y.iloc[:, permutation]\n",
    "#.reshape((1,m))\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 15000)\n",
      "(34, 15000)\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0005,\n",
    "          num_epochs = 1500, minibatch_size = 512, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a four-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 93, number of training examples = 16129)\n",
    "    Y_train -- test set, of shape (output size = 34, number of training examples = 16129)\n",
    "    X_test -- training set, of shape (input size = 93, number of training examples = 3871)\n",
    "    Y_test -- test set, of shape (output size = 34, number of test examples = 3871)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(0)                             # to keep consistent results\n",
    "    seed = 2                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #print(\"here \",X.shape)\n",
    "    Z20 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z20, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z20), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "        print (\"Train Accuracy : \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy  : \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print (\"Learning_rate  : \",learning_rate)\n",
    "        print (\"Batch Size     : \",minibatch_size)\n",
    "#         Y=tf.transpose(Y)\n",
    "#         Z20=tf.transpose(Z20)\n",
    "#         print(Y.shape,Z20.shape)\n",
    "#         confusion = tf.confusion_matrix(labels=Y, predictions=Z20, num_classes=n_y)\n",
    "#         print(confusion)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 15000)\n",
      "Cost after epoch 0: 3.645672\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy :  0.11533333\n",
      "Test Accuracy  :  0.028\n",
      "Learning_rate  :  0.0005\n",
      "Batch Size     :  512\n",
      "(?, 34) (?, 34)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape (?, 2, 34) must have rank 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    845\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    890\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" % (self,\n\u001b[0;32m--> 891\u001b[0;31m                                                                        other))\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 2, 34) and (?, ?) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 2, 34) and (?, ?) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-591d976975ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#24,20,2.14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-2aa78844f6cc>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mZ20\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/confusion_matrix.py\u001b[0m in \u001b[0;36mconfusion_matrix_v1\u001b[0;34m(labels, predictions, num_classes, dtype, name, weights)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return confusion_matrix(labels, predictions, num_classes, weights, dtype,\n\u001b[0;32m--> 258\u001b[0;31m                           name)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/confusion_matrix.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(labels, predictions, num_classes, weights, dtype, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m               if weights is None else weights)\n\u001b[1;32m    192\u001b[0m     cm_sparse = sparse_tensor.SparseTensor(\n\u001b[0;32m--> 193\u001b[0;31m         indices=indices, values=values, dense_shape=math_ops.to_int64(shape))\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mzero_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_int32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, indices, values, dense_shape)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mindices_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mdense_shape_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    921\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (?, 2, 34) must have rank 2"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "parameters = model(X_train, Y_train, X_test, Y_test,num_epochs = 50)\n",
    "#24,20,2.14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
